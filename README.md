# MetaSearch: Search-Augmented LLM with Reasoning for Consensus Resolution in Peer Review

This repository contains the implementation and data processing pipeline for the paper "MetaSearch: Search-Augmented LLM with Reasoning for Consensus Resolution in Peer Review".

## Repository Structure

```
MetaSearch/
â”œâ”€â”€ .gitignore                         # Files to ignore
â”œâ”€â”€ LICENSE                            # License info
â”œâ”€â”€ README.md                          # Overview, setup, and usage
â”œâ”€â”€ requirements.txt                   # Dependencies
â”œâ”€â”€ Supplementary Materials.pdf        # PDF of Supplementary Materials
â”œâ”€â”€ workflow_drawio.png                # Visual workflow diagram
â”œâ”€â”€ data                               # Data processing and datasets
â”‚   â”œâ”€â”€ aggregate.py                   # Aggregates extracted data
â”‚   â”œâ”€â”€ convert_json_to_csv.py         # Converts JSON files to CSV
â”‚   â”œâ”€â”€ merge_final.py                 # Merges finalized datasets
â”‚   â”œâ”€â”€ merge_search_critique.py       # Merges search results with critiques
â”‚   â”œâ”€â”€ prepare_new_subset.py          # Prepares a new dataset subset
â”‚   â”œâ”€â”€ prepare_sample_subset.py       # Prepares a sample dataset subset
â”‚   â”œâ”€â”€ processed                      # Processed data outputs
â”‚   â”‚   â”œâ”€â”€ consensus_resolution       # Consensus resolution outputs
â”‚   â”‚   â”‚   â”œâ”€â”€ aggregated_dr.csv              # Aggregated disagreement resolution data
â”‚   â”‚   â”‚   â”œâ”€â”€ aggregated_mr.csv              # Aggregated meta-review data
â”‚   â”‚   â”‚   â”œâ”€â”€ combined_final.csv             # Combined final dataset
â”‚   â”‚   â”‚   â”œâ”€â”€ disaagreement_resolution_final.csv  # Final resolution with discrepancies
â”‚   â”‚   â”‚   â”œâ”€â”€ disagreement_resolution.csv     # Disagreement resolution data
â”‚   â”‚   â”‚   â”œâ”€â”€ disagreement_resolution_final.csv# Final disagreement resolution data
â”‚   â”‚   â”‚   â”œâ”€â”€ meta_reviews.csv                # Generated meta reviews
â”‚   â”‚   â”‚   â””â”€â”€ meta_reviews_final.csv          # Final meta reviews
â”‚   â”‚   â”œâ”€â”€ critique_points            # Extracted critique points
â”‚   â”‚   â”‚   â”œâ”€â”€ critique_points_llm.json        # LLM-extracted (v1)
â”‚   â”‚   â”‚   â”œâ”€â”€ critique_points_llm_2.json      # LLM-extracted (v2)
â”‚   â”‚   â”‚   â”œâ”€â”€ critique_points_nlp.json        # NLP-extracted (v1)
â”‚   â”‚   â”‚   â””â”€â”€ critique_points_nlp_2.json      # NLP-extracted (v2)
â”‚   â”‚   â”œâ”€â”€ disagreement_detection     # Disagreement detection outputs
â”‚   â”‚   â”‚   â”œâ”€â”€ aggregated_ds_llm.csv            # LLM-based aggregated disagreement scores
â”‚   â”‚   â”‚   â”œâ”€â”€ disagreement_aggregated.csv      # Aggregated disagreement data (v1)
â”‚   â”‚   â”‚   â”œâ”€â”€ disagreement_aggregated_2.csv    # Aggregated disagreement data (v2)
â”‚   â”‚   â”‚   â”œâ”€â”€ disagreement_scores_llm.csv      # LLM disagreement scores (CSV)
â”‚   â”‚   â”‚   â”œâ”€â”€ disagreement_scores_llm.json     # LLM disagreement scores (JSON, v1)
â”‚   â”‚   â”‚   â”œâ”€â”€ disagreement_scores_llm_2.csv      # LLM disagreement scores (CSV, v2)
â”‚   â”‚   â”‚   â”œâ”€â”€ disagreement_scores_llm_2.json     # LLM disagreement scores (JSON, v2)
â”‚   â”‚   â”‚   â”œâ”€â”€ disagreement_scores_llm_2_arya.json# Alternative LLM disagreement scores
â”‚   â”‚   â”‚   â”œâ”€â”€ disagreement_scores_nlp.json       # NLP disagreement scores
â”‚   â”‚   â”‚   â””â”€â”€ metrics.csv                        # Evaluation metrics
â”‚   â”‚   â””â”€â”€ search                     # Search-retrieved evidence and logs
â”‚   â”‚       â”œâ”€â”€ aggregated_cp.json               # Aggregated critique points from search
â”‚   â”‚       â”œâ”€â”€ aggregated_papers_with_search.csv # Papers with search annotations
â”‚   â”‚       â”œâ”€â”€ critique_points_llm_2.json         # Additional LLM critique points (v2)
â”‚   â”‚       â”œâ”€â”€ drive-download-20250329T065307Z-001# Drive download (timestamped)
â”‚   â”‚       â”œâ”€â”€ logs.json                         # Search process logs
â”‚   â”‚       â”œâ”€â”€ papers_with_search_2.csv           # Papers with search results (CSV, v2)
â”‚   â”‚       â”œâ”€â”€ papers_with_search_2.json          # Papers with search results (JSON, v2)
â”‚   â”‚       â”œâ”€â”€ papers_with_search_final.csv       # Final papers with search results
â”‚   â”‚       â”œâ”€â”€ papers_with_search_initial.json    # I nitial papers with search results
â”‚   â”‚       â”œâ”€â”€ papers_with_search_progress.csv    # Search progress tracking
â”‚   â”‚       â”œâ”€â”€ search_batch_2.json                # Search results batch (v2)
â”‚   â”‚       â”œâ”€â”€ search_final_2.json                # Final search results (v2)
â”‚   â”‚       â”œâ”€â”€ search_intermediate.json           # Intermediate search results (v1)
â”‚   â”‚       â””â”€â”€ search_intermediate_2.json         # Intermediate search results (v2)
â”‚   â”œâ”€â”€ raw                           # Original, unprocessed data
â”‚   â”‚   â”œâ”€â”€ cache-2ff1e739000f2062.arrow         # Cached data (v1)
â”‚   â”‚   â”œâ”€â”€ cache-3465735dd11c43b2.arrow         # Cached data (v2)
â”‚   â”‚   â”œâ”€â”€ cache-48201879335d942f.arrow         # Cached data (v3)
â”‚   â”‚   â”œâ”€â”€ data-00000-of-00001.arrow            # Primary raw data file
â”‚   â”‚   â”œâ”€â”€ dataset_info.json                    # Dataset metadata
â”‚   â”‚   â””â”€â”€ state.json                           # Data processing state
â”‚   â”œâ”€â”€ split                         # Dataset splits (train/test/val)
â”‚   â”‚   â”œâ”€â”€ sample_subset_train.json             # Sample training subset (v1)
â”‚   â”‚   â”œâ”€â”€ sample_subset_train_2.json           # Sample training subset (v2)
â”‚   â”‚   â”œâ”€â”€ test                      # Test split
â”‚   â”‚   â”‚   â”œâ”€â”€ data-00000-of-00001.arrow        # Test data
â”‚   â”‚   â”‚   â”œâ”€â”€ dataset_info.json                # Test info
â”‚   â”‚   â”‚   â””â”€â”€ state.json                       # Test state
â”‚   â”‚   â”œâ”€â”€ test.json                            # Test metadata
â”‚   â”‚   â”œâ”€â”€ train                     # Training split
â”‚   â”‚   â”‚   â”œâ”€â”€ data-00000-of-00001.arrow        # Train data
â”‚   â”‚   â”‚   â”œâ”€â”€ dataset_info.json                # Train info
â”‚   â”‚   â”‚   â””â”€â”€ state.json                       # Train state
â”‚   â”‚   â”œâ”€â”€ train.json                           # Training metadata
â”‚   â”‚   â”œâ”€â”€ val                       # Validation split
â”‚   â”‚   â”‚   â”œâ”€â”€ data-00000-of-00001.arrow        # Validation data
â”‚   â”‚   â”‚   â”œâ”€â”€ dataset_info.json                # Validation info
â”‚   â”‚   â”‚   â””â”€â”€ state.json                       # Validation state
â”‚   â”‚   â””â”€â”€ val.json                             # Validation metadata
â”‚   â””â”€â”€ split_dataset.py                # Generates data splits
â”œâ”€â”€ figures                          # Visualizations and figures (mentioned in detail in Supplementary Materials PDF document)
â”‚   â”œâ”€â”€ Acceptance vs. Review Ratings.png
â”‚   â”œâ”€â”€ Average Disagreement Score Trend (NeurIPS and ICLR).png
â”‚   â”œâ”€â”€ Cosine similarity - Generated Meta Review vs Original Meta Review.png
â”‚   â”œâ”€â”€ Distribution of Disagreement Scores.png
â”‚   â”œâ”€â”€ Distribution of Review Lengths.png
â”‚   â”œâ”€â”€ Distribution of Reviewer Disagreements.png
â”‚   â”œâ”€â”€ Jaccard Similarity Distributions.png
â”‚   â”œâ”€â”€ Review Length Distribution by Confidence Score.png
â”‚   â”œâ”€â”€ Review Rating Distribution for Accepted vs Rejected Papers.png
â”‚   â”œâ”€â”€ SOTA Results and Paper Title Similarity Score.png
â”‚   â”œâ”€â”€ Sentiment Score Distribution for Clarity.png
â”‚   â”œâ”€â”€ Sentiment Subjectivity Histogram.png
â”‚   â””â”€â”€ figures_in_paper
â”‚       â”œâ”€â”€ Review Rating Distribution by Paper Acceptance.png
â”‚       â”œâ”€â”€ cosine.png
â”‚       â””â”€â”€ meta_review_bert.png
â”œâ”€â”€ notebooks                        # Jupyter notebooks for analysis
â”‚   â”œâ”€â”€ 01_Exploratory_Analysis.ipynb
â”‚   â”œâ”€â”€ 02_EDA_CritiqueLLM.ipynb
â”‚   â”œâ”€â”€ 03_Disagreement_Scores_LLM.ipynb
â”‚   â”œâ”€â”€ 04_Search_Result_Analysis.ipynb
â”‚   â”œâ”€â”€ 05_Retrieved_Evidences_Analysis.ipynb
â”‚   â”œâ”€â”€ 06_Disagreement_Resolution.ipynb
â”‚   â””â”€â”€ 07_Meta_Review_Comparison.ipynb
â”œâ”€â”€ src                              # Core source code
â”‚   â”œâ”€â”€ consensus_resolution
â”‚   â”‚   â”œâ”€â”€ disagreement_resolution_deepseek.py  # DeepSeek-based resolution
â”‚   â”‚   â””â”€â”€ meta_review_generation.py            # Meta review generation
â”‚   â”œâ”€â”€ critique_points_extraction
â”‚   â”‚   â”œâ”€â”€ extract_critique_llm.py               # LLM-based extraction
â”‚   â”‚   â””â”€â”€ extract_critique_nlp.py               # NLP-based extraction
â”‚   â”œâ”€â”€ disagreement_detection
â”‚   â”‚   â”œâ”€â”€ compare_reviews_llm.py                # LLM-based comparison
â”‚   â”‚   â””â”€â”€ compare_reviews_nlp.py                # NLP-based comparison
â”‚   â””â”€â”€ search_retrieval
â”‚       â”œâ”€â”€ search_agent.ipynb                    # Search agent exploration
â””       â””â”€â”€ search_agent.py                       # Search agent implementation
```

## Methodology

Our approach follows a systematic workflow:

1. Data Collection and Preprocessing
2. Search-Augmented Review Analysis
3. Consensus Detection
4. Result Validation

For detailed workflow visualization, see [workflow_drawio.png](workflow_drawio.png).

## Setup

1. Create a Python virtual environment:
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

2. Install dependencies:
```bash
pip install -r requirements.txt
```

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details. 

Research Paper: "MetaSearch: Search-Augmented LLM with Reasoning for Consensus Resolution in Peer Review" ([Back to Top](https://github.com/AnonymousSubmission45/MetaSearch/tree/main?tab=readme-ov-file#metasearch-search-augmented-llm-with-reasoning-for-consensus-resolution-in-peer-review)ğŸ”)
